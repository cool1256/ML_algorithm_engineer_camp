{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归方法简介\n",
    "\n",
    "## 形式化定义\n",
    "+ 假设函数（hypotheses function）  \n",
    "$$h_{\\theta}(x)=\\sum_{i=0}^{n} \\theta_{i} x_{i}=\\theta^{T} x$$  其中  x_{0}=1 \n",
    "+ 损失函数（loss function）  \n",
    "$$L(\\theta)=\\left(h_{\\theta}(x)-y\\right)^{2}$$\n",
    "+ 代价函数（cost function）  \n",
    "$$J(\\theta)=\\frac{1}{2 \\mathrm{m}} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 梯度下降法（Gradient Descent）\n",
    "+ 随机初始化&\\theta&\n",
    "+ 设置步长&\\alpha&, 设置迭代次数&\\m&\n",
    "+ 求&J(\\theta)&的导数$\\nabla J(\\theta)$\n",
    "+ $\\begin{array}{l}\n",
    "\\text { for } i=0 \\text { to } m \\text { : } \\\\\n",
    "\\qquad \\theta:=\\theta-\\alpha \\nabla J(\\theta)\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用梯度下降法求解线性回归问题\n",
    "+ 代价函数\n",
    "$$J(\\theta)=\\frac{1}{2 \\mathrm{m}} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$\n",
    "+ 求解\n",
    "$$\\displaylines{ \\begin{array}{l}\n",
    "\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)=\\frac{\\partial}{\\partial \\theta_{j}} \\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2} \\\\\n",
    "=2 * \\frac{1}{2 m} \\sum_{i=1}^{m}\\left[\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) \\frac{\\partial}{\\partial \\theta_{j}}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)\\right] \\\\\n",
    "=\\frac{1}{m} \\sum_{i=1}^{m}\\left[\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) \\frac{\\partial}{\\partial \\theta_{j}}\\left(\\sum_{f=0}^{n} \\theta_{f} x_{f}^{(i)}-y^{(i)}\\right)\\right] \\\\\n",
    "=\\frac{1}{m} \\sum_{i=1}^{m}\\left[\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}\\right] \\\\\n",
    "\\theta_{j}:=\\theta_{j}+\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)}\n",
    "\\end{array}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降类型\n",
    "## 批量梯度下降（Batch Gradient Descent, BGD）\n",
    "$$\\theta_{j}:=\\theta_{j}+\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)}$$\n",
    "## 随机梯度下降(Stochastic Gradient Descent, SGD)\n",
    "$$\\theta_{j}:=\\theta_{j}+\\alpha\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)}$$\n",
    "## 小批量梯度下降(Mini-Batch Gradient Descent, MBGD)\n",
    "+ 每次取batch-size个样本进行更新\n",
    "$$\\theta_{j}:=\\theta_{j}+\\frac{\\alpha}{\\text { batch-num }} \\sum_{i=1}^{\\text {bact }}\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 评价指标\n",
    "## 均方误差（MSE）\n",
    "$$M S E=\\frac{1}{m} \\sum_{i=1}^{m}\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^{2}$$\n",
    "## 均方根误差（RMSE）\n",
    "$$R M S E=\\sqrt{\\frac{1}{m} \\sum_{i=1}^{m}\\left(y^{(i)}-\\hat{y}^{(j)}\\right)^{2}}$$\n",
    "## 平均绝对误差（MAE）\n",
    "$$M A E=\\frac{1}{m} \\sum_{i=1}^{m}\\left|y^{(i)}-\\hat{y}^{(i)}\\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠拟合与过拟合\n",
    "![欠拟合和过拟合](./img/2_1.png)\n",
    "\n",
    "# [正则化](https://blog.csdn.net/qq_20412595/article/details/81636105)\n",
    "+ L2范数正则化解决过拟合（Ridge Regression, 岭回归）  \n",
    "$$J(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2} +\\lambda\\|\\theta\\|_{2}^{2} =\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2} \\quad(\\lambda>0)$$ \n",
    "\n",
    "+ L1范数正则化解决过拟合（LASSO回归）  \n",
    "$$J(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda\\|\\theta\\|_{1}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda \\sum_{j=1}^{n}|\\theta_{j}|$$  \n",
    "\n",
    "+ L1与L2结合解决过拟合（Elastic Net, 弹性网） \n",
    "$$J(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda\\left(\\rho \\|\\theta\\|_{1}+(1-\\rho)\\|\\theta\\|_{2}^{2}\\right) \\quad(\\lambda>0,0 \\leq \\rho \\leq 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ridge回归(L2)求解与代码实现\n",
    "+ 目标函数   \n",
    "$$\\displaylines{ J(\\theta)=\\frac{1}{2 \\mathrm{m}} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda\\|\\theta\\|_{2}^{2} \\\\ =\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(0)}\\right)-y^{(0)}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta}$$\n",
    "+ 岭回归求解   \n",
    "$$\\displaylines{\\begin{array}{l}\n",
    "\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)=\\frac{\\partial}{\\partial \\theta_{j}} \\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(j)}\\right)-y^{(i)}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2} \\\\\n",
    "=\\frac{1}{m} \\sum_{i=1}^{m}\\left[\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(n)}\\right]+2 \\lambda \\theta_{j}\n",
    "\\end{array}}$$\n",
    "+ 迭代公式   \n",
    "$$\\theta_{j}:=\\theta_{j}+\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)}-2 \\lambda \\theta_{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lasso回归（L1）求解与代码实现\n",
    "+ 目标函数  \n",
    "$$J(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+\\lambda|\\theta|_{1}$$\n",
    "去掉系数转化：   \n",
    "$$J(\\theta)=\\sum_{i=1}^{m}\\left(y^{(i)}-\\sum_{j=0}^{n} \\theta_{j} x_{j}^{(i)}\\right)^{2}+\\lambda \\sum_{j=0}^{n}\\left|\\theta_{j}\\right| \\quad(\\lambda>0)$$\n",
    "+ 残差求解（目标函数第一部分）  \n",
    "$$\\displaylines{\\begin{array}{l}\n",
    "\\frac{\\partial}{\\partial \\theta_{k}} R S S(\\theta)=2 \\sum_{i=1}^{m}\\left(y^{(i)}-\\sum_{j=0}^{n} \\theta_{j} x_{j}^{(i)}\\right)\\left(-x_{k}^{(i)}\\right) \\\\\n",
    "=-2 \\sum_{i=1}^{m}\\left(x_{k}^{(i)} y^{(i)}-x_{k}^{(i)} \\sum_{j=0}^{n} \\theta_{j} x_{j}^{(i)}\\right) \\\\\n",
    "=-2 \\sum_{i=1}^{m}\\left(x_{k}^{(i)} y^{(i)}-x_{k}^{(i)} \\sum_{j=0, j \\neq k}^{n} \\theta_{j} x_{j}^{(i)}-\\theta_{k} x_{k}^{(i)^{2}}\\right) \\\\\n",
    "=-2 \\sum_{i=1}^{m}\\left[\\left(x_{k}^{(i)}\\left(y^{(i)}-\\sum_{j=0, j \\neq k}^{n} \\theta_{j} x_{j}^{(i)}\\right)\\right]+2 \\theta_{k} \\sum_{i=1}^{m} x_{k}^{(i)^{2}}\\right.\n",
    "\\end{array}}$$\n",
    "\n",
    "$$\\text {令： }p_{k}=\\sum_{i=1}^{m}\\left[\\left(x_{k}^{(i)}\\left(y^{(i)}-\\sum_{j=0, j \\neq k}^{n} \\theta_{j} x_{j}^{(i)}\\right)\\right]\\right.$$\n",
    "$$z_{k}=\\sum_{i=1}^{m} x_{k}^{(0)^{2}}$$\n",
    "$$\\text {则： }\\frac{\\partial}{\\partial \\theta_{k}} R S S(\\theta)=-2 p_{k}+2 \\theta_{k} z_{k}$$\n",
    "+ 正则项求偏导   \n",
    "$$\\frac{\\partial}{\\partial \\theta_{k}} R(\\theta)=\\left\\{\\begin{array}{ll}\n",
    "-\\lambda & \\theta_{k}<0 \\\\\n",
    "{[-\\lambda, \\lambda]} & \\theta_{k}=0 \\\\\n",
    "\\lambda & \\theta_{k}>0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "+ 整体求偏导  \n",
    "$$\\frac{\\partial}{\\partial \\theta_{k}} J(\\theta)=-2 p_{k}+2 \\theta_{k} z_{k}+\\left\\{\\begin{array}{ll}\n",
    "-\\lambda & v_{k}<0 \\\\\n",
    "{[-\\lambda, \\lambda]} & \\theta_{k}=0 \\\\\n",
    "\\lambda & \\theta_{k}>0\n",
    "\\end{array}=\\{\\begin{array}{ll}\n",
    "-2 p_{k}+2 \\theta_{k} z_{k}-\\lambda & \\theta_{k}<0 \\\\\n",
    "{\\left[-2 p_{k}-\\lambda,-2 p_{k}+\\lambda\\right]} & \\theta_{k}=0 \\\\\n",
    "-2 p_{k}+2 \\theta_{k} z_{k}+\\lambda & \\theta_{k}>0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\text { 令: } \\frac{\\partial}{\\partial \\theta_{k}} J(\\theta)=0 \\text { 得 }: \\\\\n",
    "\\theta_{k}=\\left\\{\\begin{array}{ll}\n",
    "\\left(p_{k}+\\lambda / 2\\right) / z_{k} & p_{k}<-\\lambda / 2 \\\\\n",
    "0 & -\\lambda / 2 \\leq p_{k} \\leq \\lambda / 2 \\\\\n",
    "\\left(p_{k}-\\lambda / 2\\right) / z_{k} & p_{k}>\\lambda / 2\n",
    "\\end{array}\\right.\n",
    "\\end{array}$$\n",
    "\n",
    "+ 最终迭代公式\n",
    "$$p_{k}=\\sum_{i=1}^{m}\\left[\\left(x_{k}^{(i)}\\left(y^{(i)}-\\sum_{j=0, j \\neq k}^{n} \\theta_{j} x_{j}^{(i)}\\right)\\right]\\right.$$\n",
    "$$z_{k}=\\sum_{i=1}^{m} x_{k}^{(i)^{2}}$$\n",
    "\n",
    "$$\\theta_{k}=\\left\\{\\begin{array}{l}\n",
    "\\left(p_{k}+\\lambda / 2\\right) / z_{k} & p_{k}<-\\lambda / 2 \\\\\n",
    "0 & -\\lambda / 2 \\leq p_{k} \\leq \\lambda / 2 \\\\\n",
    "\\left(p_{k}-\\lambda / 2\\right) / z_{k} & p_{k}>\\lambda / 2\n",
    "\\end{array}\\right.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO回归求解实例\n",
    "\n",
    "|面积|朝向|价格|\n",
    "|-|-|-|\n",
    "|200|1|305|\n",
    "|120|2|130|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 损失函数\n",
    "$$J(\\theta)=\\frac{1}{2} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵运算中用到的公式。小宁字母表示向量，大写字母表示矩阵  \n",
    "\n",
    "$$(a b)^{T}=b^{T} a^{T}$$\n",
    "$$\\frac{\\partial\\left(x^{T} A x\\right)}{\\partial x}=2 A x$$\n",
    "$$\\frac{\\partial\\left(x^{T} A\\right)}{\\partial x}=A$$\n",
    "$$\\frac{\\partial(A x)}{\\partial x}=A^{T}$$\n",
    "$$A^{-1} A=1$$\n",
    "\n",
    "---\n",
    "$$\\begin{array}{l}\n",
    "J(\\theta)=\\frac{1}{2}(X \\theta-y)^{T}(X \\theta-y) \\\\\n",
    "=\\frac{1}{2}\\left(\\theta^{T} X^{T}-y^{T}\\right)(X \\theta-y) \\\\\n",
    "=\\frac{1}{2}\\left(\\theta^{T} X^{T} X \\theta-\\theta^{T} X^{T} y-y^{T} X \\theta+y^{T} y\\right)\n",
    "\\end{array}$$  \n",
    "---\n",
    "$$\\begin{array}{l}\n",
    "\\nabla_{\\theta} J(\\theta)=\\frac{1}{2}\\left(2 X^{T} X \\theta-X^{T} y-\\left(y^{T} X\\right)^{\\mathrm{T}}\\right) \\\\\n",
    "=X^{T} X \\theta-X^{T} y\n",
    "\\end{array}$$\n",
    "---\n",
    "$$\\begin{array}{l}\n",
    "\\text { 令 } \\nabla_{\\theta} J(\\theta)=0 \\\\\n",
    "X^{T} X \\theta-X^{T} y=0 \\\\\n",
    "\\left(X^{T} X\\right)^{-1} X^{T} X \\theta=\\left(X^{T} X\\right)^{-1} X^{T} y \\\\\n",
    "\\theta=\\left(X^{T} X\\right)^{-1} X^{T} y\n",
    "\\end{array}$$\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
